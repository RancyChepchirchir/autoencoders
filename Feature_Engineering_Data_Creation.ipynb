{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Engineering Data Creation.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XlvgjhFPhteM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction: Autoencoders with Keras tutorial\n",
        "\n",
        "In this notebook, we will follow along with the [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html) tutorial. This tutorial was written by Francois Chollet, one of the core developers of Keras."
      ]
    },
    {
      "metadata": {
        "id": "TMJOuoK-3TwZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxKfgBERiPq4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle &> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkktTC_uiqjt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUCjAfuS5kYz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -r /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TNATbB6jNKO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cd ~\n",
        "!mkdir /content/.kaggle\n",
        "!mv kaggle.json  /content/.kaggle\n",
        "!kaggle datasets download -d moltean/fruits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iCkHVffojpMt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/.kaggle/datasets/moltean/fruits/'*.zip' -d /datasets/ &> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTHF6nLnoRMt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the AutoEncoder"
      ]
    },
    {
      "metadata": {
        "id": "FLaznFqfoOKa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Dimensions for encoding\n",
        "encoding_dim = 300\n",
        "\n",
        "# The input image will be flattened to 100 * 100 * 3\n",
        "input_img = Input(shape=(100 * 100 * 3, ))\n",
        "\n",
        "# Encoded representation\n",
        "encoded = Dense(encoding_dim, activation = 'relu')(input_img)\n",
        "\n",
        "# Decoded output\n",
        "decoded = Dense(100 * 100 * 3, activation = 'sigmoid')(encoded)\n",
        "\n",
        "# Complete autoencoder\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Just the encoder\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# Create a separate input for encoding layer\n",
        "encoded_input = Input(shape = (encoding_dim, ))\n",
        "\n",
        "# Create a separate decoding layer\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "\n",
        "# Decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TTusl-2oo8sQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eI94_bwPphTI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator()\n",
        "\n",
        "generator = datagen.flow_from_directory('/datasets/fruits-360/Training/',\n",
        "                                         target_size = (100, 100), batch_size = 1)\n",
        "\n",
        "index_to_label = {value: key for key, value in generator.class_indices.items()}\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "i = 0\n",
        "for batch in generator:\n",
        "  # First index is the image, second index is the batch\n",
        "  images.append(batch[0][0])\n",
        "  labels.append(index_to_label.get(np.where(batch[1][0])[0][0], 'Not found'))\n",
        "  i += 1\n",
        "  if i > 10000:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gYIquFl0z_qy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "valid_datagen = ImageDataGenerator()\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory('/datasets/fruits-360/Validation/',\n",
        "                                                    target_size = (100, 100), batch_size = 1)\n",
        "\n",
        "valid_index_to_label = {value: key for key, value in valid_generator.class_indices.items()}\n",
        "\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "\n",
        "i = 0\n",
        "for batch in valid_generator:\n",
        "  # First index is the image, second index is the batch\n",
        "  valid_images.append(batch[0][0])\n",
        "  valid_labels.append(valid_index_to_label.get(np.where(batch[1][0])[0][0], 'Not found'))\n",
        "  i += 1\n",
        "  if i > 1000:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfp3xQDYqik4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-ZuOUaHyF6r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = np.array(images)\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "print('Training Images Shape: ', x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4EQRk1g0Vq9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_valid = np.array(valid_images)\n",
        "x_valid = x_valid.astype('float32') / 255.\n",
        "\n",
        "x_valid = x_valid.reshape((len(x_valid), np.prod(x_valid.shape[1:])))\n",
        "print('Validation Images Shape: ', x_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w-AaBK-Xq6Ba",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the autoencoder to learn a 32 dimension representation of the images\n",
        "autoencoder.fit(x_train, x_train, epochs = 50, batch_size = 256,\n",
        "                shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLtT9PRm1ARo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reconstruct Images from the Test Data"
      ]
    },
    {
      "metadata": {
        "id": "hsegfFNNz4BK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Encode the validation images\n",
        "encoded_images = encoder.predict(x_valid)\n",
        "\n",
        "# Decode the validation images\n",
        "decoded_images = decoder.predict(encoded_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cdzAXrMD1Q0C",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10\n",
        "\n",
        "plt.figure(figsize = (20, 4))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  # Need to reshape the image back to 3 color channels\n",
        "  plt.imshow(x_test[i].reshape((100, 100, 3)))\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  \n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  # Reshape the reconstructed image\n",
        "  plt.imshow(decoded_images[i].reshape((100, 100, 3)))\n",
        "  \n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALfAPd9H1-qA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}